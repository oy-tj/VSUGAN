{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/opt/anaconda3/lib/python38.zip')\n",
    "sys.path.append('/opt/anaconda3/lib/python3.8')\n",
    "sys.path.append('/opt/anaconda3/lib/python3.8/lib-dynload')\n",
    "sys.path.append('/home/oytj/.local/lib/python3.8/site-packages')\n",
    "sys.path.append('/opt/anaconda3/lib/python3.8/site-packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "from matplotlib import pyplot as plt \n",
    "import IPython\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "import pyworld\n",
    "import pysptk\n",
    "import model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## 数据预处理\n",
    "### 读入干净的长音频，重采样为16384,分割4s小段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    clean_voc_seg=[]\n",
    "    sr16k=16384\n",
    "    path='./data/train/wav'\n",
    "    savePath='./data/train/sr16k'\n",
    "    filenames=os.listdir(path)\n",
    "    filenames.sort()\n",
    "    fileHead=\"\"\n",
    "    temp_voc_seg=[]\n",
    "    for i in range(len(filenames)): \n",
    "        filename=filenames[i]\n",
    "        if filename[-4:]=='.wav':\n",
    "            if (fileHead!=filename.split('_')[0]):\n",
    "                if len(temp_voc_seg)>0:\n",
    "                    clean_voc_seg.append(np.array(temp_voc_seg))\n",
    "                    saveName='speaker_'+fileHead+'.npy'\n",
    "                    print('\\nSave',saveName)\n",
    "                    np.save(savePath+'/'+saveName,np.array(temp_voc_seg))\n",
    "                    temp_voc_seg=[]\n",
    "                fileHead=filename.split('_')[0]\n",
    "                    #if(i>2000):\n",
    "                    #    break\n",
    "            print('[{}/{}]reading     {}...     '.format(i+1,len(filenames),filename),end='\\r' )\n",
    "            src_voc, sr = librosa.load(path+'/'+filename,sr=None)#读取\n",
    "            print('[{}/{}]resampleing {}...     '.format(i+1,len(filenames),filename),end='\\r' )\n",
    "            src_voc_16k=librosa.resample(src_voc,sr,sr16k)#重采样\n",
    "            print('[{}/{}]spliting    {}...     '.format(i+1,len(filenames),filename),end='\\r' )\n",
    "            seconds=math.floor(len(src_voc_16k)/sr16k)\n",
    "            for j in range(0,seconds-4,5):\n",
    "                temp_voc_seg.append(src_voc_16k[j*sr16k:(j+4)*sr16k])\n",
    "        if len(temp_voc_seg)>0:\n",
    "            clean_voc_seg.append(np.array(temp_voc_seg))\n",
    "            saveName='speaker_'+fileHead+'.npy'\n",
    "            #print('\\nSave',saveName)\n",
    "            np.save(savePath+'/'+saveName,np.array(temp_voc_seg))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取保存的音频array，节约时间\n",
    "clean_voc_seg=[]\n",
    "savePath='./data/train/sr16k'\n",
    "filenames=os.listdir(savePath)\n",
    "filenames.sort()\n",
    "for i in range(len(filenames)): \n",
    "    filename=filenames[i]\n",
    "    print('[{}/{}]reading     {}...     '.format(i+1,len(filenames),filename),end='\\r' )\n",
    "    read_arr = np.load(savePath+'/'+filename)\n",
    "    clean_voc_seg.append(read_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(clean_voc_seg))\n",
    "clean_voc_seg[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读入噪声"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_seg=[]\n",
    "sr16k=16384\n",
    "path=r'./data/train/noise'\n",
    "for subname in os.listdir(path):\n",
    "    subpath=path+'/'+subname\n",
    "    for filename in os.listdir(subpath):\n",
    "        if filename[-4:]=='.wav':\n",
    "            print('reading '+filename+'...   ',end='\\r' )\n",
    "            n, sr = librosa.load(subpath+'/'+filename,sr=None)\n",
    "            n16k=librosa.resample(n,sr,sr16k)\n",
    "            if len(n16k)>5*sr16k:\n",
    "                noise_seg.append(n16k[sr16k:5*sr16k])\n",
    "for i in range(len(noise_seg)):\n",
    "    stdMax=1.0\n",
    "    srcMax=noise_seg[i].max()\n",
    "    noise_seg[i]=noise_seg[i]*stdMax/srcMax\n",
    "noise_seg=np.array(noise_seg)\n",
    "noise_seg.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 时频转换与显示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FFT = 512\n",
    "def wav2spectrum(wav):\n",
    "    S = librosa.stft(wav, N_FFT)\n",
    "    p = np.angle(S)\n",
    "    S = np.log1p(np.abs(S))\n",
    "    return S\n",
    "\n",
    "def spectrum2wav(spectrum):\n",
    "    a = np.exp(spectrum) - 1\n",
    "    p = 2 * np.pi * np.random.random_sample(spectrum.shape) - np.pi\n",
    "    for i in range(50):\n",
    "        S = a * np.exp(1j * p)\n",
    "        x = librosa.istft(S)\n",
    "        p = np.angle(librosa.stft(x, N_FFT))\n",
    "    return x\n",
    "\n",
    "def disWavSpec(wav,title='wavform',colorbar=False):\n",
    "    spec=wav2spectrum(wav)\n",
    "    plt.figure(figsize=(10, 14))\n",
    "    plt.title(title)\n",
    "    plt.subplot(2,1,1),librosa.display.waveplot(wav, sr=sr16k),plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(2,1,2),librosa.display.specshow(spec, sr=sr),plt.xticks([]), plt.yticks([])\n",
    "    #plt.subplot(2,1,2),librosa.display.specshow(spec, sr=sr, x_axis='time', y_axis='mel'),plt.xticks([]), plt.yticks([])\n",
    "    if colorbar:\n",
    "        plt.colorbar()\n",
    "    plt.show()\n",
    "    return IPython.display.Audio(wav,rate=sr16k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练数据生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectrumOpt(spectrum,opt='',kernelSize=(3,3)):\n",
    "    if opt=='':\n",
    "        opt=random.randint(0,7)\n",
    "    if(opt==0):#平均滤波\n",
    "        dst = cv.blur(spectrum,kernelSize)\n",
    "    elif(opt==1):#中值滤波\n",
    "        dst = cv.medianBlur(spectrum,kernelSize[0])\n",
    "    elif(opt==2):#高斯滤波\n",
    "        dst = cv.GaussianBlur(spectrum,kernelSize,0)\n",
    "    elif(opt==3):#双边滤波\n",
    "        dst = cv.bilateralFilter(spectrum,kernelSize[0],75,75)\n",
    "    elif(opt==4):#腐蚀\n",
    "        kernel = np.ones(kernelSize,np.uint8)\n",
    "        dst = cv.erode(spectrum,kernel,iterations = 1)\n",
    "    elif(opt==5):#膨胀\n",
    "        kernel = np.ones(kernelSize,np.uint8)\n",
    "        dst = cv.dilate(spectrum,kernel,iterations = 1)\n",
    "    elif(opt==6):#开\n",
    "        kernel = np.ones(kernelSize,np.uint8)\n",
    "        dst = cv.morphologyEx(spectrum,cv.MORPH_OPEN,kernel)\n",
    "    elif(opt==7):#闭\n",
    "        kernel = np.ones(kernelSize,np.uint8)\n",
    "        dst = cv.morphologyEx(spectrum,cv.MORPH_CLOSE,kernel)\n",
    "    return dst\n",
    "#####################################################\n",
    "#增加全局变量用来替代random\n",
    "#干净声音集合，噪声集合，batchSize，是否为训练数据，指定的演讲者，指定的噪声，是否使用图形学处理混合音频频谱\n",
    "def getData(clean_voc_seg,noise_seg,batch_size,Training=True,Speaker='',Noise='',mixedAudioOpt=True):\n",
    "    noise=None\n",
    "    style=None\n",
    "    label=None\n",
    "    split=int((len(clean_voc_seg))*0.85)\n",
    "    for i in range(batch_size):\n",
    "        #随机抽取音频数据、风格数据、噪声数据\n",
    "        if Speaker!='':\n",
    "            speakerNo=Speaker[0]\n",
    "            datNo=Speaker[1]\n",
    "            styNo=Speaker[2]\n",
    "        else:\n",
    "            if Training==True:\n",
    "                speakerNo=random.randint(0,split-1)\n",
    "            else:\n",
    "                speakerNo=random.randint(split,len(clean_voc_seg)-1)\n",
    "            datNo,styNo=random.sample(range(0,len(clean_voc_seg[speakerNo])-1),2)\n",
    "\n",
    "        #合成音频与噪声,噪声强度随机\n",
    "        if Noise!='':\n",
    "            noiseNo=Noise[0]\n",
    "            noiseAm=Noise[1]\n",
    "        else:\n",
    "            noiseNo=random.randint(0,len(noise_seg)-1)\n",
    "            noiseAm=random.uniform(0.0,0.3)\n",
    "        w_noise=clean_voc_seg[speakerNo][datNo]+(noise_seg[noiseNo]*noiseAm)\n",
    "        w_style=clean_voc_seg[speakerNo][styNo]\n",
    "        w_label=clean_voc_seg[speakerNo][datNo]\n",
    "        s_noise=wav2spectrum(w_noise)\n",
    "        if mixedAudioOpt==True:\n",
    "            s_noise=spectrumOpt(s_noise)\n",
    "        elif type(mixedAudioOpt)==type(0):\n",
    "             s_noise=spectrumOpt(s_noise,opt=mixedAudioOpt)   \n",
    "        s_style=wav2spectrum(w_style)\n",
    "        s_label=wav2spectrum(w_label)\n",
    "        t_noise=torch.from_numpy(s_noise.reshape(1,1,s_noise.shape[0],s_noise.shape[1]))\n",
    "        t_style=torch.from_numpy(s_style.reshape(1,1,s_style.shape[0],s_style.shape[1]))\n",
    "        t_label=torch.from_numpy(s_label.reshape(1,1,s_label.shape[0],s_label.shape[1]))\n",
    "        if(noise==None):\n",
    "            noise=t_noise\n",
    "            style=t_style\n",
    "            label=t_label\n",
    "        else:\n",
    "            noise=torch.cat((noise, t_noise), dim=0)\n",
    "            style=torch.cat((style, t_style), dim=0)\n",
    "            label=torch.cat((label, t_label), dim=0)\n",
    "    if torch.cuda.is_available():\n",
    "        mixedAudio=noise.cuda()\n",
    "        style=style.cuda()\n",
    "        label=label.cuda()\n",
    "    #返回：带噪声的音频，风格模板，干净的音频，噪音编号，（说话者编号，讲话内容编号，风格音频编号，噪声编号）\n",
    "    return mixedAudio,style,label,(speakerNo,datNo,styNo,noiseNo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadNet=True\n",
    "loadNetName='./trainedModel/Gan4-best.pth'\n",
    "saveNetPath='./trainedModel/'\n",
    "train_loss_set=[]\n",
    "val_loss_set=[]\n",
    "val_Match_set=[]\n",
    "#新建网络\n",
    "discriminator=model.Discriminator()\n",
    "generator=model.Generator()\n",
    "optimizerG = torch.optim.Adam(generator.parameters(), lr=0.001) # optimizer 使用 Adam\n",
    "#optimizerG=torch.optim.RMSprop(generator.parameters(), lr=0.0001)\n",
    "g_lambda = 10  # regularizer for generator\n",
    "optimizerD = torch.optim.Adam(discriminator.parameters(), lr=0.0001)\n",
    "#optimizerD = torch.optim.RMSprop(discriminator.parameters(), lr=0.0001)\n",
    "if loadNet==True:\n",
    "    #从文件读取网络\n",
    "    savedNet=torch.load(loadNetName)\n",
    "    generator.load_state_dict(savedNet['netG'])\n",
    "    discriminator.load_state_dict(savedNet['netD'])\n",
    "    #optimizerG.load_state_dict(savedNet['optimizerG'])\n",
    "    #optimizerD.load_state_dict(savedNet['optimizerD'])\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    discriminator=discriminator.cuda()\n",
    "    generator=generator.cuda()\n",
    "loss=nn.L1Loss()\n",
    "minLossID=-1.0\n",
    "minLossVar=100.0\n",
    "totle_epoch=1247####接着上一次\n",
    "d_update=True\n",
    "def setNewRange(srcTensor,stdTensor):\n",
    "    for i in range(srcTensor.size()[0]):\n",
    "        stdMax=float(torch.max(stdTensor[i]))\n",
    "        srcMax=float(torch.max(srcTensor[i]))\n",
    "        srcTensor[i]=srcTensor[i]*stdMax/srcMax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(batch_size,d_epoch_size,g_epoch_size):    \n",
    "    global discriminator\n",
    "    global generator\n",
    "    global optimizerG\n",
    "    global g_lambda\n",
    "    global optimizerD\n",
    "    global minLossID\n",
    "    global minLossVar\n",
    "    global totle_epoch\n",
    "    global d_update\n",
    "    torch.cuda.empty_cache()\n",
    "    epoch_start_time = time.time()\n",
    "    discriminator.train()\n",
    "    generator.train()\n",
    "    train_loss = 0.0\n",
    "    val_loss = 0.0\n",
    "    dtLoss=0.0\n",
    "    for i in range(d_epoch_size):\n",
    "        if d_update==False:\n",
    "            break\n",
    "        xn,xs,yl,_=getData(clean_voc_seg,noise_seg,batch_size,Training=True)#抽取训练数据\n",
    "        #训练Discriminator\n",
    "        discriminator.zero_grad()\n",
    "        # TRAIN D to recognize generated audio as noisy\n",
    "        generated_outputs = generator(xn, xs)\n",
    "        outputs = discriminator(generated_outputs,xn)\n",
    "        noisy_loss = 10*torch.mean(outputs ** 2)  # L2 loss - we want them all to be 0\n",
    "        noisy_loss.backward()\n",
    "        \n",
    "        # TRAIN D to recognize clean audio as clean\n",
    "        setNewRange(yl,generated_outputs)\n",
    "        outputs = discriminator(yl,xn)\n",
    "        clean_loss = 10*torch.mean((outputs - 1.0) ** 2)  # L2 loss - we want them all to be 1\n",
    "        clean_loss.backward()\n",
    "        optimizerD.step()\n",
    "        dtLoss=dtLoss+noisy_loss+clean_loss\n",
    "        print(\"1.D:batch {:0>3d}/{:0>3d} in epoch {:0>3d}/{:0>3d} Loss={:.10f}\".format(i+1,d_epoch_size,epoch+1,epochs,(clean_loss+noisy_loss)/batch_size),end='\\r')\n",
    "    dtLoss/=(d_epoch_size*batch_size)\n",
    "    '''\n",
    "    if dtLoss>0.05:\n",
    "        print('[%03d/%03d-%03d] %3.2f sec(s) dtLoss:%3.6f Skip Train Generater' % \\\n",
    "            (epoch + 1, epochs,totle_epoch, time.time()-epoch_start_time, \\\n",
    "             dtLoss),'                    '\\\n",
    "         )\n",
    "        return\n",
    "    '''\n",
    "    sum_g_loss_=0\n",
    "    for i in range(g_epoch_size):\n",
    "        #训练Generator\n",
    "        xn,xs,yl,_=getData(clean_voc_seg,noise_seg,batch_size,Training=True)#抽取训练数据\n",
    "        # TRAIN G so that D recognizes G(z) as real\n",
    "        generator.zero_grad()\n",
    "        generated_outputs = generator(xn, xs)\n",
    "        setNewRange(yl,generated_outputs)\n",
    "        outputs = discriminator(generated_outputs,xn)\n",
    "        _g_loss_ = 0.5 * torch.mean((outputs - 1.0) ** 2)\n",
    "        sum_g_loss_+=_g_loss_.item()\n",
    "        \n",
    "        l1_loss=loss(generated_outputs, yl)\n",
    "        g_loss=( _g_loss_ + g_lambda * l1_loss)*2\n",
    "        g_loss.backward()\n",
    "        optimizerG.step()\n",
    "        \n",
    "        #batch_loss = loss(generated_outputs, yl)\n",
    "        train_loss += g_loss.item()\n",
    "        print('2.G:batch {:0>3d}/{:0>3d} in epoch {:0>3d}/{:0>3d} G_loss={:.10f} L1_loss{:.10f}'.format(i+1,g_epoch_size,epoch+1,epochs,_g_loss_/batch_size,l1_loss/batch_size),end='\\r')\n",
    "    sum_g_loss_/=(g_epoch_size*batch_size)\n",
    "    state={\n",
    "        'netG':generator.state_dict(),\n",
    "        'optimizerG':optimizerG.state_dict(),\n",
    "        'netD':discriminator.state_dict(),\n",
    "        'optimizerD':optimizerD.state_dict(),\n",
    "    }\n",
    "    torch.save(state,saveNetPath+ 'Gan4-last.pth')\n",
    "    \n",
    "    if sum_g_loss_>0.05:\n",
    "        d_update=False\n",
    "    else:\n",
    "        d_update=True\n",
    "        state={\n",
    "            'netG':generator.state_dict(),\n",
    "            'optimizerG':optimizerG.state_dict(),\n",
    "            'netD':discriminator.state_dict(),\n",
    "            'optimizerD':optimizerD.state_dict(),\n",
    "        }\n",
    "        torch.save(state, saveNetPath+'Gan4-best.pth')\n",
    "    trainTime=time.time()-epoch_start_time\n",
    "    print('[%03d/%03d-%03d] %3.2f sec(s) Train Loss: %3.6f |d_update:' % \\\n",
    "            (epoch + 1, epochs,totle_epoch, trainTime, \\\n",
    "            train_loss/(batch_size*g_epoch_size)),\\\n",
    "            d_update,sum_g_loss_,'       '\n",
    "         )\n",
    "    totle_epoch+=1  \n",
    "    #测试\n",
    "    if epoch%100 == 0:\n",
    "        testLoss=0.00\n",
    "        for i in range(10):\n",
    "            xn,xs,yl,_=getData(clean_voc_seg,noise_seg,batch_size,Training=False)#抽取测试数据\n",
    "            generator.zero_grad()\n",
    "            generated_outputs = generator(xn, xs)\n",
    "            setNewRange(yl,generated_outputs)\n",
    "            outputs = discriminator(generated_outputs,xn)\n",
    "            _g_loss_ = 0.5 * torch.mean((outputs - 1.0) ** 2)\n",
    "            l1_loss=loss(generated_outputs, yl)\n",
    "            g_loss=( _g_loss_ + g_lambda * l1_loss)*2\n",
    "            testLoss += g_loss.item()\n",
    "        print('%3.2f sec(s) Test Loss: %3.6f ' % \\\n",
    "            (time.time()-trainTime, testLoss/(batch_size*10)))\n",
    "            \n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=5  #5\n",
    "d_epoch_size=1 #每个世代训练的batchs\n",
    "g_epoch_size=30 #\n",
    "epochs = 3000 \n",
    "for epoch in range(epochs):\n",
    "    train(batch_size,d_epoch_size,g_epoch_size)\n",
    "    torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "无",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
